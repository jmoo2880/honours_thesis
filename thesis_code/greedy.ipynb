{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of greedy forward feature selection for instance space analysis\n",
    "Algorithm:\n",
    "- Start with empty feature set\n",
    "- Evaluate performance of model using each feature individually\n",
    "- Add the feature which results in the greatest improvement in performance to current set of features\n",
    "- Repeat previous 2 steps until stopping criterion is met (performance improvement drops below some threshold, delta performance is no longer statitstically significant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.2, shuffle = True, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3) # estimator\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n",
    "sfs.fit(X,y)\n",
    "subset = sfs.transform(X)\n",
    "sfs.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyForwardSelection():\n",
    "\n",
    "    def __init__(self, k_features):\n",
    "        self.k_features = k_features # target number of features, termination conditon\n",
    "        #self.model = clone(model)\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "        max_idx = tuple(range(X_train.shape[1])) # get feature idxs\n",
    "        total_features_count = len(max_idx) # initial num of features\n",
    "        self.subsets_ = list()\n",
    "        self.scores_ = list()\n",
    "        self.indices_ = list()\n",
    "\n",
    "        scores = list()\n",
    "        subsets = list()\n",
    "        \n",
    "        for p in combinations(max_idx, r=1):\n",
    "            # train on all possible first features\n",
    "            score = self._calc_score(X_train, X_test, y_train, y_test, p)\n",
    "            scores.append(score)\n",
    "            subsets.append(p)\n",
    "\n",
    "        best_score_idx = np.argmax(scores)\n",
    "        self.scores_.append(scores[best_score_idx])\n",
    "        self.indices_ = list(subsets[best_score_idx])\n",
    "        self.subsets_.append(self.indices_)\n",
    "\n",
    "        # add features sequentially until k_features is reached\n",
    "        current_k = 1\n",
    "        while current_k < self.k_features:\n",
    "            scores = list()\n",
    "            subsets = list()\n",
    "\n",
    "            idx = 0\n",
    "            while idx < total_features_count:\n",
    "                if idx not in self.indices_:\n",
    "                    indices = list(self.indices_)\n",
    "                    indices.append(idx)\n",
    "                    score = self._calc_score(X_train, X_test, y_train, y_test, indices)\n",
    "                    scores.append(score)\n",
    "                    subsets.append(indices)\n",
    "                idx += 1\n",
    "            \n",
    "            best_score_idx = np.argmax(scores)\n",
    "            self.scores_.append(scores[best_score_idx])\n",
    "            self.indices_ = list(subsets[best_score_idx])\n",
    "            self.subsets_.append(self.indices_)\n",
    "            current_k += 1\n",
    "        \n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "    # output data matrix using reduced subset of features\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    ##def _calc_score(self, X_train, X_test, y_train, y_test, indices):\n",
    "       # self.model.fit(X_train[:, indices], y_train)\n",
    "       # score = self.model.score(X_test[:, indices], y_test)\n",
    "       # return score\n",
    "\n",
    "    # add custom calc score function for pca\n",
    "    def _calc_score(self, X_train, X_test, y_train, y_test, indices):\n",
    "        epsilon_range = np.linspace(0.05, 2, 100)\n",
    "        components = len(indices)\n",
    "        accuracies = list()\n",
    "\n",
    "        # train model\n",
    "        pca_fit = PCA(n_components=components).fit(X_train[:, indices])\n",
    "        pca_train = pca_fit.transform(X_train[:, indices])\n",
    "\n",
    "        # project test instances\n",
    "        pca_test = pca_fit.transform(X_test[:, indices])\n",
    "\n",
    "        for epsilon in epsilon_range:\n",
    "            predictions = list()\n",
    "            for test_instance in pca_test:\n",
    "                neighbours_idx = np.argwhere(np.linalg.norm(pca_train - test_instance, axis=1) < epsilon)\n",
    "\n",
    "                # if no neighbouring points in epsilon radius, use 1-NN\n",
    "                if len(neighbours_idx) == 0:\n",
    "                    distances = np.linalg.norm(pca_train - test_instance, axis=1)\n",
    "                    neighbours_idx = np.argmin(distances)\n",
    "                \n",
    "                neighbour_pts = y_train[neighbours_idx]\n",
    "                unique, counts = np.unique(neighbour_pts, return_counts=True)\n",
    "                pred = unique[np.argmax(counts)]\n",
    "                predictions.append(pred)\n",
    "            matches = np.count_nonzero(predictions == y_test)\n",
    "            acc = matches / len(y_test)\n",
    "            accuracies.append(acc)\n",
    "        \n",
    "        best_score = np.max(accuracies) # return max acc achieved across all epsilons\n",
    "        return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('isa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a41f742c31b0955ce3f6a3df41e9249c8f0cae08b8916b3250138db157ba78a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
